{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Nework\n",
    "here we try to write a simple neural network to understand what backpropagation really do :)\n",
    "## Now we create a simple one layer newtork "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### continue our feedforward network and make it a complete neural network that can predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.4946683 ]\n",
      " [ 0.48067154]\n",
      " [ 0.50842225]\n",
      " [-0.50655747]]\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      "[[ 0.4946683 ]\n",
      " [ 0.51932846]\n",
      " [ 0.49157775]\n",
      " [ 0.50655747]]\n"
     ]
    }
   ],
   "source": [
    "#activation funcion\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "#derivative of activation funcion\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1.0 - x)\n",
    "    #return sigmoid(x) * (1.0 - sigmoid(x)) #laut Folien ist das die Formel\n",
    "\n",
    "#class of your neural network\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    #set features of your neural network\n",
    "    def __init__(self, x, y):\n",
    "        self.input      = x\n",
    "        self.weights1   = np.random.rand(self.input.shape[1],2)\n",
    "        self.weights2   = np.random.rand(2,1)          \n",
    "        self.y          = y\n",
    "        self.output     = np.zeros(self.y.shape)\n",
    "    #feedfarward function \n",
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "    #backpropagate the error\n",
    "    def backprop(self):\n",
    "        # application of the chain rule to find derivative of the Error with respect to weights2 and weights1\n",
    "        d_weights2 = np.dot(self.layer1.T, ((self.y - self.output) * sigmoid_derivative(self.output)))\n",
    "        d_weights1 = np.dot(self.input.T,  (np.dot((self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1)))\n",
    "\n",
    "        # update the weights with the derivative (slope) of the loss function\n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2\n",
    "\n",
    "#Test what you have done :D \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X = np.array([[0,0,1],\n",
    "                  [0,1,1],\n",
    "                  [1,0,1],\n",
    "                  [1,1,1]])\n",
    "    y = np.array([[0],[1],[1],[0]])\n",
    "   \n",
    "    nn = NeuralNetwork(X, y) # make instance of your NerualNetwork class\n",
    "   \n",
    "    #do the iteration for learning\n",
    "    for i in range(100):\n",
    "        nn.feedforward()\n",
    "        nn.backprop()\n",
    "        \n",
    "    print(nn.y - nn.output)\n",
    "    print(nn.y)\n",
    "    print(nn.output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0,0,1],\n",
    "                  [0,1,1],\n",
    "                  [1,0,1],\n",
    "                  [1,1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18800682,  0.6602511 ],\n",
       "       [ 0.19546521,  0.63628758],\n",
       "       [ 0.65732607,  0.70565005]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights1   = np.random.rand(X.shape[1],2)\n",
    "weights1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.65732607,  0.70565005],\n",
       "       [ 0.85279128,  1.34193763],\n",
       "       [ 0.84533289,  1.36590115],\n",
       "       [ 1.0407981 ,  2.00218873]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X, weights1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Useful Libraries\n",
    "Simple Example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [[0], [1]]\n",
    "clf = MLPClassifier()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict([[1, 2]]))\n",
    "print(clf.predict([[0, 0]]))\n",
    "print(clf.predict([[1, 1]]))\n",
    "print(clf.predict([[0, 2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR Function\n",
    "Let us start with a simple example of Boolean OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "import sklearn.metrics as metric\n",
    "import numpy as np\n",
    "\n",
    "X_training=[]\n",
    "y_training=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_training=[[1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_training=[1, \n",
    "            1,\n",
    "            1,\n",
    "            0\n",
    "           ]\n",
    "mlp = MLPClassifier() # set the method\n",
    "mlp.fit(X_training, y_training)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(mlp.predict([[0,0]]))\n",
    "print(mlp.predict([[0,1]]))\n",
    "print(mlp.predict([[1,0]]))\n",
    "print(mlp.predict([[1,1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice: Bipolar OR\n",
    "\n",
    "Instead of {0, 1}, we can also change the value into bipolar {-1, +1}. Try the following OR gate using Perceptron and MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_training=[[1, 1], \n",
    "            [1, -1],\n",
    "            [-1, 1],\n",
    "            [-1, -1]\n",
    "           ]\n",
    "y_training=[1, \n",
    "            1,\n",
    "            1,\n",
    "            -1\n",
    "           ]\n",
    "X_testing=X_training\n",
    "y_true=y_training\n",
    "\n",
    "mlp_bipolar = MLPClassifier() # set the method\n",
    "mlp_bipolar.fit(X_testing, y_true)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(mlp_bipolar.predict([[-1,-1]]))\n",
    "print(mlp_bipolar.predict([[-1,1]]))\n",
    "print(mlp_bipolar.predict([[1,-1]]))\n",
    "print(mlp_bipolar.predict([[1,1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Networks\n",
    "\n",
    "The following code is the example of how you will use Multi-Layer Perceptron (MLP) Neural Network to train, predict. You can also get the weights of the Neural Network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1 -1]\n",
      "[(2, 100), (100, 1)]\n",
      "[array([[ -3.22822008e-01,   1.20305555e-02,   1.17372650e-02,\n",
      "          1.20601169e-01,   2.68552268e-01,  -4.47320236e-03,\n",
      "         -3.18317541e-01,  -2.28098078e-06,  -3.49666255e-01,\n",
      "          2.81863053e-01,   1.16775119e-01,   3.48459140e-01,\n",
      "          1.66627409e-06,  -3.24137001e-01,  -4.32288629e-06,\n",
      "         -3.44608013e-01,  -2.56885499e-01,   1.66877938e-01,\n",
      "          2.13712192e-01,   4.22646806e-01,   5.49503530e-08,\n",
      "          3.13876901e-02,   1.94767681e-01,  -1.69470911e-01,\n",
      "         -2.80068872e-02,  -8.52902785e-02,  -1.06174363e-01,\n",
      "         -3.13852587e-01,   2.21425352e-01,   1.83824759e-01,\n",
      "          3.13288598e-01,   1.13580632e-01,  -4.78991125e-02,\n",
      "          4.32703936e-01,  -3.34498694e-02,  -1.36247328e-01,\n",
      "          3.80892361e-01,  -1.08533972e-01,  -2.99841271e-02,\n",
      "          2.32771676e-01,  -1.67115211e-01,  -5.00496749e-02,\n",
      "          1.90930461e-01,   2.14841599e-02,  -2.70999173e-03,\n",
      "         -2.98719164e-01,  -1.25748074e-02,  -7.44543932e-02,\n",
      "         -2.88662353e-07,  -1.48261889e-01,   3.58396762e-01,\n",
      "          1.83087971e-01,   9.91989116e-02,  -2.90281850e-01,\n",
      "          2.57594486e-01,   3.40377297e-02,  -3.38394724e-07,\n",
      "          1.00513984e-01,  -1.89990130e-01,   8.08006255e-02,\n",
      "         -7.66944947e-02,   1.03808291e-01,  -3.87631658e-02,\n",
      "         -2.82431938e-01,   3.33276904e-01,  -1.37065492e-01,\n",
      "         -2.60361495e-02,   1.74643008e-01,   7.20752392e-02,\n",
      "         -1.81151574e-01,   1.74055163e-01,  -1.61366769e-01,\n",
      "          2.57545045e-01,   1.28388652e-01,  -1.13488001e-01,\n",
      "          1.20937700e-04,   1.89624385e-06,   3.59593333e-01,\n",
      "          3.00648763e-01,  -2.96708362e-01,  -3.21368827e-01,\n",
      "         -1.07850506e-01,  -1.17994623e-01,   4.90268095e-02,\n",
      "          3.76076996e-02,   1.60209637e-01,  -3.24043406e-01,\n",
      "          9.76017114e-02,  -2.02914755e-01,  -1.21711741e-01,\n",
      "          5.95544058e-02,   2.18686893e-01,  -3.53800246e-02,\n",
      "          3.35596523e-01,  -7.78534421e-02,   5.53622336e-02,\n",
      "          2.33783501e-02,  -3.20322338e-01,   3.41561084e-01,\n",
      "         -1.33481196e-01],\n",
      "       [ -3.57580443e-01,   2.70435788e-01,  -1.56247863e-01,\n",
      "          4.02489890e-01,   1.78495561e-01,   1.92665979e-01,\n",
      "         -3.18939966e-01,  -1.68721743e-07,  -3.86051829e-01,\n",
      "         -1.11930007e-02,   1.45635379e-01,  -6.68283961e-02,\n",
      "         -2.18087512e-06,  -1.09021044e-01,   1.57666639e-07,\n",
      "         -3.51938989e-01,   3.34080111e-01,  -2.00318800e-01,\n",
      "          2.20438887e-01,  -2.94898346e-01,  -7.09139930e-03,\n",
      "          5.75235535e-02,   2.84744627e-01,  -1.14970342e-01,\n",
      "          1.51309987e-01,   2.50904789e-01,   3.28037753e-02,\n",
      "          2.77665576e-02,  -1.88813449e-01,   4.66623044e-02,\n",
      "          4.18530806e-02,   8.92119172e-02,  -5.20016981e-02,\n",
      "         -3.46780741e-01,  -4.09802898e-02,  -3.72042231e-01,\n",
      "         -1.13543360e-01,   1.37030974e-01,  -3.39924668e-01,\n",
      "          8.88997314e-02,  -2.24252182e-01,  -1.21829516e-01,\n",
      "         -1.34634289e-01,  -4.93307111e-02,  -3.55323154e-07,\n",
      "         -3.14243620e-01,  -2.68564719e-07,  -5.48365421e-02,\n",
      "          8.53739865e-04,   3.28095934e-02,  -1.93532433e-01,\n",
      "          9.58063350e-02,   7.51451295e-02,  -2.10886560e-01,\n",
      "         -2.86110499e-02,   1.25581369e-01,   1.23805435e-03,\n",
      "          1.29502318e-01,  -2.82506546e-01,  -1.92432816e-01,\n",
      "          5.01318208e-02,   2.99643971e-01,  -1.00834395e-01,\n",
      "          2.28005933e-01,  -1.22322484e-01,   9.06462985e-03,\n",
      "         -1.60758023e-01,   1.07665464e-01,  -2.49556899e-01,\n",
      "         -2.50422333e-01,   9.86080938e-02,   1.19528920e-01,\n",
      "         -1.89313996e-01,  -2.82681438e-01,   3.74848380e-01,\n",
      "         -1.77588432e-01,  -1.11091602e-03,  -1.28509714e-01,\n",
      "         -1.65386887e-01,  -9.55852376e-02,  -2.41151785e-01,\n",
      "          2.11027297e-01,   3.53197135e-01,  -1.80660618e-01,\n",
      "          1.61397468e-01,  -2.05110475e-01,  -5.96725828e-02,\n",
      "          2.69981595e-01,  -3.99809159e-01,   3.10316658e-01,\n",
      "          4.65454106e-03,  -8.25455835e-02,  -3.53228199e-01,\n",
      "          3.30905481e-01,   3.49652746e-01,  -1.18547836e-02,\n",
      "         -1.76321071e-08,  -4.07872397e-01,   3.33538851e-01,\n",
      "          3.27828061e-01]]), array([[ -2.17257892e-01],\n",
      "       [  3.21299280e-01],\n",
      "       [ -1.45145473e-01],\n",
      "       [  1.86966177e-01],\n",
      "       [  2.86739569e-01],\n",
      "       [ -1.60536787e-01],\n",
      "       [ -2.21905657e-01],\n",
      "       [ -3.56880026e-02],\n",
      "       [ -2.22353836e-01],\n",
      "       [  2.52801040e-01],\n",
      "       [  3.73498024e-01],\n",
      "       [  2.70240632e-01],\n",
      "       [ -2.14221149e-02],\n",
      "       [ -2.57177015e-01],\n",
      "       [  2.74384737e-04],\n",
      "       [ -2.70842841e-01],\n",
      "       [  2.89601642e-01],\n",
      "       [  3.51097867e-01],\n",
      "       [  2.78373666e-01],\n",
      "       [  1.58011499e-01],\n",
      "       [ -3.17423186e-02],\n",
      "       [ -1.31103224e-01],\n",
      "       [  3.50845977e-01],\n",
      "       [ -2.08814478e-01],\n",
      "       [ -4.74344501e-02],\n",
      "       [  2.89648340e-01],\n",
      "       [ -1.85895221e-01],\n",
      "       [ -1.70414239e-01],\n",
      "       [  2.29222726e-01],\n",
      "       [ -9.91008563e-02],\n",
      "       [  2.68398406e-01],\n",
      "       [ -4.17739689e-02],\n",
      "       [  9.77357545e-02],\n",
      "       [  1.82525024e-01],\n",
      "       [  7.12714960e-02],\n",
      "       [ -2.49321578e-01],\n",
      "       [  2.87316440e-01],\n",
      "       [  2.56297987e-01],\n",
      "       [ -1.01181821e-01],\n",
      "       [  3.44090340e-01],\n",
      "       [ -3.97409340e-01],\n",
      "       [ -2.31867451e-01],\n",
      "       [  8.39808668e-02],\n",
      "       [ -2.84799321e-02],\n",
      "       [ -2.77301710e-07],\n",
      "       [ -2.77730904e-01],\n",
      "       [  4.22240174e-02],\n",
      "       [  4.90768948e-02],\n",
      "       [  8.32901012e-03],\n",
      "       [ -1.77814840e-02],\n",
      "       [  1.80165750e-01],\n",
      "       [  3.42608416e-01],\n",
      "       [ -4.90480207e-03],\n",
      "       [ -2.75521837e-01],\n",
      "       [  2.00371974e-01],\n",
      "       [  4.16878540e-01],\n",
      "       [ -1.38264518e-03],\n",
      "       [ -9.21354815e-02],\n",
      "       [ -2.94142012e-01],\n",
      "       [ -2.91310726e-02],\n",
      "       [  2.27034179e-01],\n",
      "       [  1.43140447e-01],\n",
      "       [  1.30190324e-01],\n",
      "       [  2.40850169e-01],\n",
      "       [  1.23334373e-01],\n",
      "       [ -9.95568208e-02],\n",
      "       [  6.68904901e-02],\n",
      "       [  6.12429266e-02],\n",
      "       [ -9.66877162e-02],\n",
      "       [ -8.69257645e-02],\n",
      "       [  2.31679773e-01],\n",
      "       [ -1.21226667e-01],\n",
      "       [  4.30666291e-01],\n",
      "       [  1.85393535e-02],\n",
      "       [  3.18553594e-01],\n",
      "       [ -4.11964724e-02],\n",
      "       [  3.09023786e-04],\n",
      "       [  1.94818607e-01],\n",
      "       [  3.16313205e-01],\n",
      "       [ -3.58949374e-01],\n",
      "       [ -3.35361281e-01],\n",
      "       [  3.73574035e-01],\n",
      "       [  4.22431239e-01],\n",
      "       [ -1.30857637e-01],\n",
      "       [ -1.74700565e-01],\n",
      "       [  3.46031280e-01],\n",
      "       [ -2.20103057e-01],\n",
      "       [  2.02084627e-01],\n",
      "       [ -2.44609683e-01],\n",
      "       [  3.10330083e-01],\n",
      "       [ -1.57892180e-01],\n",
      "       [  3.71233934e-01],\n",
      "       [ -2.56412961e-01],\n",
      "       [  3.17050638e-01],\n",
      "       [  3.28155587e-01],\n",
      "       [  1.17406646e-03],\n",
      "       [  1.91939292e-02],\n",
      "       [ -1.65200976e-01],\n",
      "       [  2.23260725e-01],\n",
      "       [  3.14874137e-01]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlp = MLPClassifier() # set the method\n",
    "mlp.fit(X_training, y_training)                    # training\n",
    "y_pred=mlp.predict(X_training)                      # prediction\n",
    "print(y_pred)                                      # show the output\n",
    "print([coef.shape for coef in mlp.coefs_])  # size of synapsis weights\n",
    "print(mlp.coefs_)                                 # synapsis weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now your Turn!\n",
    "### Experiments\n",
    "\n",
    "-  Change the data (X_training, y_training, X_testing)\n",
    "-  Change the hidden layer of MLP: number of layers (int) or size (n,m)\n",
    "-  Change activation function of MLP: {'identity', 'logistic',...}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "import sklearn.metrics as metric\n",
    "import numpy as np\n",
    "\n",
    "X_training=[[1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_training=[1, \n",
    "            1,\n",
    "            1,\n",
    "            0\n",
    "           ]\n",
    "\n",
    "X_testing = X_training\n",
    "y_true = y_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n",
      "acuracy= 0.75\n",
      "[(2, 200), (200, 100), (100, 300), (300, 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(200,100,300), activation='logistic') # set the method\n",
    "mlp.fit(X_training, y_training)                    # training\n",
    "y_pred=mlp.predict(X_testing)                      # prediction\n",
    "print(y_pred)                                      # show the output\n",
    "accuracy=metric.accuracy_score(np.array(y_true).flatten(), np.array(y_pred).flatten(), normalize=True)\n",
    "print('acuracy=', accuracy)                         # show accracy score\n",
    "\n",
    "\n",
    "print([coef.shape for coef in mlp.coefs_])  # size of synapsis weights\n",
    "len(mlp.coefs_) \n",
    "\n",
    "# 2 neurons auf 200 auf 100 auf 300 auf 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XNOR \n",
    "Try solve the following Boolean Exclusive Not Or (XNOR) problem. How to improve the accuracy? How many minimum hidden layer is needed to make it 100% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training=[[1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_training=[0, \n",
    "            0,\n",
    "            0,\n",
    "            1\n",
    "           ]\n",
    "X_testing=X_training\n",
    "y_true=y_training    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1]\n",
      "[0 0 0 0]\n",
      "acuracy= 0.75\n",
      "[(2, 50), (50, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(50)) # set the method\n",
    "mlp.fit(X_training, y_training)                    # training\n",
    "y_pred=mlp.predict(X_testing)\n",
    "                                      # show the output\n",
    "print(np.array(y_true).flatten())\n",
    "print(np.array(y_pred).flatten())\n",
    "accuracy=metric.accuracy_score(np.array(y_true).flatten(), np.array(y_pred).flatten(), normalize=True)\n",
    "print('acuracy=',accuracy)                         # show accracy score\n",
    "\n",
    "\n",
    "print([coef.shape for coef in mlp.coefs_])  # size of synapsis weights\n",
    "len(mlp.coefs_)                                  # synapsis weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = pd.read_csv(\"iris.csv\")\n",
    "train=pd.get_dummies(train)\n",
    "features = train.columns[:-1]\n",
    "y = train.columns[-1]\n",
    "Y =(train[y])\n",
    "X = train[features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5)\n",
    "nn = MLPClassifier()\n",
    "nn.fit(X_train,y_train)\n",
    "nn.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "Creat your network based on only two features of the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97333333333333338"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your answer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"iris.csv\")\n",
    "features = train.columns[:-1]\n",
    "X = train[features]\n",
    "Y =train['Species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5)\n",
    "nn = MLPClassifier()\n",
    "a = nn.fit(X_train,y_train)\n",
    "nn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to create and train a nerural network for a given dataset with higher accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.70666666666666667"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your answer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"iris.csv\")\n",
    "features = train.columns[:-1]\n",
    "X = train[features]\n",
    "Y =train['Species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5)\n",
    "nn = MLPClassifier()\n",
    "a = nn.fit(X_train,y_train)\n",
    "nn.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
