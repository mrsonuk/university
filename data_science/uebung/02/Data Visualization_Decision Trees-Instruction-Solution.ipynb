{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization and Decision Trees\n",
    "In this instruction, you will learn how to use python as a powerful tool for data visualization and making decision trees.\n",
    "## Requirements\n",
    "Before starting instruction, you should make sure that you have installed following libraries:\n",
    "- Pandas\n",
    "- Seaborn\n",
    "- Numpy\n",
    "- Matplotlib\n",
    "- Scipy\n",
    "- Sklearn\n",
    "- Subprocess\n",
    "- Graphviz\n",
    "\n",
    "If you have installed “Anaconda”, all these libraries should be installed on your system along with “Anaconda”. You can check availability of a library by the following command:\n",
    "- python -c \"import {name of library}\"\n",
    "\n",
    "For example to check if “Numpy” is installed or not you can use the following command:\n",
    "- python -c \"import numpy\"\n",
    "\n",
    "In case there is any missing library, you can install it by the following command:\n",
    "- pip install {name of library}\n",
    "    \n",
    "If you have not installed “Graphviz” package, in the following link you can find the right package with respect to your operation system.\n",
    "- https://www.graphviz.org/download/\n",
    "\n",
    "# Data Visualization \n",
    "Data visualization is the very beginning and important topic in data science which refers to the graphical representation of information and data by using visual elements like charts, graphs, maps, and etc. In this instruction for data visualization, we will discuss following topics:\n",
    "1.\tBasic statistical analysis\n",
    "2.\tSimple plots by Numpy/Pandas\n",
    "3.\tGenerating sample data\n",
    "4.\tBox plots\n",
    "5.\tDistributions\n",
    "    - Plotting univariate distributions\n",
    "    - Plotting bivariate distributions\n",
    "    - Pair plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Statistical Analysis\n",
    "In this section, you will learn how to obtain some basic statistical values like; mean, median, and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "\n",
    "#Providing data set\n",
    "print(sns.get_dataset_names())\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "tips_10 = tips[:10]\n",
    "print(tips_10)\n",
    "\n",
    "#Some basic statistics\n",
    "print(np.mean(tips_10['total_bill'])) #mean for the 'total_bill' of the first 10 rows\n",
    "print(np.std(tips_10['total_bill'])) #standard diviation for the 'total_bill' of the first 10 rows \n",
    "print(np.var(tips_10['total_bill'])) #variance for the 'total_bill' of the first 10 rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Plots by Numpy/Pandas\n",
    "Numpy/Pandas have simple plot method which can be used to draw simple plots like; bar plot, stacked plot, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Plot\n",
    "A bar chart or bar graph is a chart or graph that presents categorical data with rectangular bars with heights or lengths proportional to the values that they represent. It can show the relationship between a numerical variable and a categorical variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Numpy/Pandas for drawing simple plots\n",
    "tips['total_bill'][:10].plot(kind='bar', figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Plot\n",
    "A stacked bar graph (or stacked bar chart)  is a chart that uses bars to show comparisons between categories of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating data set\n",
    "df = pd.DataFrame(columns=[\"Language\",\"Scripting\", \"Cross Platform\",\"Fast\",\n",
    "                           \"Data Science\",\"Easy\"], \n",
    "                  data=[[\"Python\",1,1,1,1,1],\n",
    "                        [\"Java\",0,1,1,1,0],\n",
    "                        [\"PHP\",1,1,0,0,1],\n",
    "                        [\"Perl\",1,1,1,0,1],\n",
    "                        [\"C#\",0,0,0,0,0]])\n",
    "#drawing stacked bar plot\n",
    "df.set_index('Language').plot(kind='bar', stacked=True, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More advanced bar plot by **seaborn** (y axis shows a statistical value called estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "\n",
    "#Providing data set for testing\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "#Using seaborn for drawing more complicated bar plot (default estimator is mean)\n",
    "sns.barplot(x=\"day\", y=\"total_bill\", data=tips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing estimator to median\n",
    "sns.barplot(x=\"day\", y=\"total_bill\", data=tips, estimator=np.median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Sample Data Via Random (Numpy)\n",
    "Numpy can be used to generate sample data with different distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sample1 = np.random.rand(50) * 100 #Generate 50 random data between [0,100)\n",
    "print(\"Sampl1:\\n\")\n",
    "print(sample1)\n",
    "sample2 = np.ones(25) * 50  #Generate an array with size 25, all values are 1\n",
    "print(\"Sample2:\\n\")\n",
    "print(sample2)\n",
    "sample3 = np.random.rand(10) * 100 + 100\n",
    "sample4 = np.random.rand(10) * -100\n",
    "data = np.concatenate((sample1, sample2, sample3, sample4), 0)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Plots\n",
    "A box plot or boxplot is a method for graphically depicting groups of numerical data through their quartiles.Box plots may also have lines extending vertically from the boxes (whiskers) indicating variability outside the upper and lower quartiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#notched plot, displays a confidence interval around the median which is normally based on the median +/- 1.57 x IQR/sqrt of n\n",
    "plt.boxplot(data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Color and shape of outliers\n",
    "plt.boxplot(data, 0, 'gd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the orientation (vertical, horizontal)\n",
    "plt.boxplot(data, 0, 'rs', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple box plots together\n",
    "data = [data, data[:50],sample1]\n",
    "plt.boxplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn\n",
    "<ol>\n",
    "  <li>Load \"flights\" data set by seaborn. </li>\n",
    "  <li>Calculate mean, median, and standard diviation of \"passengers\" for the first 100 rows.</li>\n",
    "  <li>Show average number of passengers per month (bar plot) for the whole data set.</li>\n",
    "  <li>Explore outliers of \"passengers\" (box plot) in the whole data set, is there any outlier?</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your answer\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "flights = sns.load_dataset(\"flights\")\n",
    "flights_100 = flights[:100]\n",
    "print(np.mean(flights_100['passengers']))\n",
    "print(np.median(flights_100['passengers']))\n",
    "print(np.std(flights_100['passengers']))\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.barplot(x=\"month\", y=\"passengers\", data=flights)\n",
    "\n",
    "plt.figure()\n",
    "plt.boxplot(flights['passengers'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributions\n",
    "The distribution of a statistical data set (or a population) is a listing or function showing all the possible values (or intervals) of the data and how often they occur.\n",
    "## Plotting Univariate Distributions\n",
    "In univariate, distribution of just one variable is explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    " \n",
    "sns.set(color_codes=True)\n",
    " \n",
    "x = np.random.normal(10,1,size=100)\n",
    "sns.distplot(x);   #default distribution with histogram and kernel density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without kernel density, with rug plot\n",
    "sns.distplot(x, kde=False, rug=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying number of bins\n",
    "sns.distplot(x, bins=20, kde=False, rug=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without histogram, with rug plot\n",
    "sns.distplot(x, hist=False, rug=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aditional features for rug, kde, and hist\n",
    "sns.distplot(x, rug=True, \n",
    "             rug_kws={\"color\": \"r\"}, \n",
    "             kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"}, \n",
    "             hist_kws={\"histtype\": \"step\", \"linewidth\": 3, \"alpha\": 1, \"color\": \"g\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Bivariate Distributions\n",
    "In this section, we will explore distribution involving two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mean = [0, 1] \n",
    "cov = [(1, .5), (.5, 1)]\n",
    "#Generate 200 random normal data based predefined mean and covariane\n",
    "data = np.random.multivariate_normal(mean, cov, 200)\n",
    "\n",
    "\n",
    "#convert Numpy to Dataframe with specific names for columns \n",
    "df = pd.DataFrame(data, columns=[\"x\", \"y\"])\n",
    "#print(df.corr())\n",
    "\n",
    "sns.jointplot(x=\"x\", y=\"y\", data=df, kind=\"kde\");  #kind= scatter, hex, reg,kde \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing type to Scatter\n",
    "scatter = sns.jointplot(x=\"x\", y=\"y\", data=df, kind=\"scatter\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding colors and labels\n",
    "scatter = sns.jointplot(x=\"x\", y=\"y\", data=df, kind=\"scatter\", joint_kws = {\"color\": ['red', 'blue']}); \n",
    "scatter.ax_joint.set_xlabel('x_red', fontweight='bold')\n",
    "scatter.ax_joint.set_ylabel('y_blue', fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing type to Hexagons\n",
    "sns.jointplot(x=\"x\", y=\"y\", data=df, kind=\"hex\");  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing type to Regression\n",
    "sns.jointplot(x=\"x\", y=\"y\", data=df, kind=\"reg\");  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair Plot\n",
    "By pair plot, we will create a grid of Axes such that each variable in data will by shared in the y-axis across a single row and in the x-axis across a single column. The diagonal Axes are treated differently, drawing a plot to show the univariate distribution of the data for the variable in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "iris[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By default all numeric variables are used\n",
    "sns.pairplot(iris); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify specific variables\n",
    "sns.pairplot(iris, vars = ['petal_length','sepal_length']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Color\n",
    "sns.pairplot(iris, hue = 'species');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding markers\n",
    "sns.pairplot(iris, hue = 'species', markers=[\"o\", \"s\", \"D\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn :)\n",
    "<ol>\n",
    "  <li>Load \"mpg\" data set by seaborn. </li>\n",
    "  <li>Show distribution of \"horsepower\" and \"acceleration\" together (by scatter plot, and different colors for each variable). Interpret the correlation between \"horsepower\" and \"acceleration\"</li>\n",
    "  <li>Represent correlation of \"horsepower\", \"weight\", and \"acceleration\" (by a pair plot). Use \"origin\" as a resource for coloring</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your answer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpg = sns.load_dataset(\"mpg\")\n",
    "sns.jointplot(x=\"horsepower\", y=\"acceleration\", data=mpg, kind=\"scatter\", joint_kws = {\"color\": ['red', 'blue']}); \n",
    "sns.pairplot(mpg, vars = ['horsepower','weight','acceleration'], hue = 'origin');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "A decision tree is a tree where each node represents a feature(attribute), each link(branch) represents a decision(rule) and each leaf represents an outcome(categorical or continues value). In the following, you can find criteria you have learned during the lecture like; Information Gain (IG), Gain Ratio (GR), and Gini. \n",
    "\n",
    "\n",
    "$\n",
    "H(t) ={-\\sum_{i=1}^l (P(t=i) \\times {log_2} {P(t=i)})}\n",
    "$\n",
    "\n",
    "$\n",
    "IG_{Entrpy}(a) = Entropy_{First} - Entropy_{splitting}\n",
    "$ \n",
    "\n",
    "$\n",
    "GR(d,D) ={ \\frac{IG(d,D)}{ - \\sum_{l \\in levels(d)} (P(d=l) \\times {log_2} {P(d=l)})}}\n",
    "$\n",
    "\n",
    "$\n",
    "Gini(t,D) ={1 - \\sum_{l \\in levels(t)} {P(t=l)}^2 }\n",
    "$\n",
    "\n",
    "$\n",
    "IG_{Gini}(a) = Gini_{First} - Gini_{splitting}\n",
    "$\n",
    "\n",
    "This part includes following topics:\n",
    "- Loading data\n",
    "- Identifying descriptive and target features\n",
    "- Identifying parameters to make the desired tree (algorithm, pruning, etc)\n",
    "- Using “Graphviz” to visualize the resulted tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "You can simply load “csv” or “excel” data by the corresponding methods (“read_csv”, “read_excel” respectively) of Pandas. before executing following code, you should make sure that you have uploaded the file in the home page of your Jupyter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DataFrame = pd.read_excel('ManWoman.xlsx')\n",
    "DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Descriptive and Target Features\n",
    "As you know based on the concepts of decision tree, descriptive features and target feature should be specified. Descriptive features are used to make a decision about the target feature. In the code descriptive features have been specified by array “X” and target feature has specified by “Y”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#descriptive features\n",
    "X = DataFrame[['height','weight']] \n",
    "#target feature\n",
    "Y = DataFrame[[\"Class\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Parameters to Make The Desired Tree (Algorithm and Pruning)\n",
    "“DecisionTreeClassifier” method of “sklearn” is used to generate tree classifier. You can set the parameters of this method based on what you need. In the following you can find some of the most important parameters of this method:\n",
    "- Main parameters to specify the algorithm\n",
    "    - Criterion: The function to measure the quality of a split. Supported criteria are \"gini\" for the Gini impurity and \"entropy\" for the information gain. (Default = \"gini\")\n",
    "    - Splitter: The strategy used to choose the split at each node. Supported strategies are \"best\" to choose the best split and \"random\" to choose the best random split. (Default = \"best\")\n",
    "- Parameters to control growth of the tree (Pruning)\n",
    "    - Min_samples_split: The minimum number of samples required to split an internal node\n",
    "    - Min_samples_leaf: The minimum number of samples required to be at a leaf node. (Default = 1)\n",
    "    - Max_depth: The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than “min_samples_split” samples. (Default = None)\n",
    "    - Max_leaf_nodes: Grow a tree with “max_leaf_nodes” in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes. (Default = None)\n",
    "    - Min_impurity_decrease: A node will be split if this split induces a decrease of the impurity greater than or equal to this value. (Default = 0.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "job_classifier = tree.DecisionTreeClassifier(criterion=\"entropy\")   \n",
    "job_classifier.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using “Graphviz” to Visualize The Resulted Tree\n",
    "In the final step, we will use “dot” tool of “Graphviz” to convert the resulted dot file (a description about the nodes and edges) to a visual decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import check_output\n",
    "\n",
    "column_names = list(DataFrame.columns.values)\n",
    "del column_names[-1]\n",
    "dot_file = \"Classification.dot\"\n",
    "pdf_file = \"Classification.pdf\"\n",
    "with open(dot_file, \"w\") as f:\n",
    "    f = tree.export_graphviz(job_classifier, out_file=f, \n",
    "                                 feature_names= column_names, \n",
    "                                 class_names=[\"Man\", \"Woman\"], \n",
    "                                 filled=True, rounded=True)\n",
    "try:\n",
    "    check_output(\"dot -Tpdf \"+ dot_file + \" -o \" + pdf_file , shell=True)\n",
    "except:\n",
    "    print(\"Make sure that you have installed Graphviz, otherwise you can not see the visual tree. But you can find descriptions in a dot file\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afte executing all the above-mentioned codes step by step, you can find the results as \"Classification.dot\" (description) and \"Classification.pdf\" (visual tree) in the home page of your Jupyter."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "©PADS-RWTH (use only with permission & acknowledgements)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
