{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Nework\n",
    "here we try to write a simple neural network to understand what backpropagation really do :)\n",
    "## Now we create a simple one layer newtork "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### continue our feedforward network and make it a complete neural network that can predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-c75ce557c583>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-c75ce557c583>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    self.input      =\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#activation funcion\n",
    "\n",
    "#deivative of activation funcion\n",
    "\n",
    "#class of your neural network\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    #set features of your neural network\n",
    "    def __init__(self, x, y):\n",
    "        self.input      = \n",
    "        self.weights1   = \n",
    "        self.weights2   =                  \n",
    "        self.y          = \n",
    "        self.output     = \n",
    "    #feedfarward function \n",
    "    def feedforward(self):\n",
    "        self.layer1 = \n",
    "        self.output = \n",
    "    #backpropagate the error\n",
    "    def backprop(self):\n",
    "        # application of the chain rule to find derivative of the Error with respect to weights2 and weights1\n",
    "        d_weights2 = \n",
    "        d_weights1 =\n",
    "\n",
    "        # update the weights with the derivative (slope) of the loss function\n",
    "        self.weights1 = \n",
    "        self.weights2 =\n",
    "\n",
    "#Test what you have done :D \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X = np.array([[0,0,1],\n",
    "                  [0,1,1],\n",
    "                  [1,0,1],\n",
    "                  [1,1,1]])\n",
    "    y = np.array([[0],[1],[1],[0]])\n",
    "   \n",
    "    nn = # make instance of your NerualNetwork class\n",
    "   \n",
    "    #do the iteration for learning\n",
    "   \n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.50000023]\n",
      " [ 0.49770154]\n",
      " [ 0.49959911]\n",
      " [-0.50244279]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#activation funcion\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1+ np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1.0 - x)\n",
    "#class of your neural network\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    #set features of your neural network\n",
    "    def __init__(self, x, y):\n",
    "        self.input      = x\n",
    "        self.weights1   = np.random.rand(self.input.shape[1],2) \n",
    "        self.weights2   = np.random.rand(2,1)                 \n",
    "        self.y          = y\n",
    "        self.output     = np.zeros(self.y.shape)\n",
    "    #feedforward function \n",
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "    #backpropagate the error\n",
    "    def backprop(self):\n",
    "        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
    "        d_weights2 = np.dot(self.layer1.T, ((self.y - self.output) * sigmoid_derivative(self.output)))\n",
    "        d_weights1 = np.dot(self.input.T,  (np.dot((self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1)))\n",
    "\n",
    "        # update the weights with the derivative (slope) of the loss function\n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2\n",
    "\n",
    "#Test what you have done :D \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X = np.array([[0,0,1],\n",
    "                  [0,1,1],\n",
    "                  [1,0,1],\n",
    "                  [1,1,1]])\n",
    "    y = np.array([[0],[1],[1],[0]])\n",
    "    \n",
    "    nn = NeuralNetwork(X,y)\n",
    "\n",
    "    for i in range(100):\n",
    "        nn.feedforward()\n",
    "        nn.backprop()\n",
    "\n",
    "    print(nn.y - nn.output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Useful Libraries\n",
    "Simple Example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [[0], [1]]\n",
    "clf = MLPClassifier()\n",
    "clf.fit(X, y)                         \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR Function\n",
    "Let us start with a simple example of Boolean OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "import sklearn.metrics as metric\n",
    "import numpy as np\n",
    "\n",
    "X_training=[]\n",
    "y_training=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "import sklearn.metrics as metric\n",
    "import numpy as np\n",
    "\n",
    "X_training=[[1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_training=[1, \n",
    "            1,\n",
    "            1,\n",
    "            0\n",
    "           ]\n",
    "mlp = MLPClassifier() # set the method\n",
    "mlp.fit(X_training, y_training)  \n",
    "mlp.predict([[1,1]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice: Bipolar OR\n",
    "\n",
    "Instead of {0, 1}, we can also change the value into bipolar {-1, +1}. Try the following OR gate using Perceptron and MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_training=[[1, 1], \n",
    "            [1, -1],\n",
    "            [-1, 1],\n",
    "            [-1, -1]\n",
    "           ]\n",
    "y_training=[1, \n",
    "            1,\n",
    "            1,\n",
    "            -1\n",
    "           ]\n",
    "X_testing=X_training\n",
    "y_true=y_training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Networks\n",
    "\n",
    "The following code is the example of how you will use Multi-Layer Perceptron (MLP) Neural Network to train, predict. You can also get the weights of the Neural Network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1 -1]\n",
      "[(2, 100), (100, 1)]\n",
      "[array([[ -5.48874571e-04,  -2.60865763e-01,   3.52015583e-02,\n",
      "          1.61367017e-03,  -3.09758919e-01,   1.83033526e-01,\n",
      "         -1.60446667e-01,   3.15868426e-01,  -2.83613853e-01,\n",
      "          7.24446253e-03,  -2.65435660e-01,   3.42878671e-02,\n",
      "          1.20573354e-01,   3.03794826e-01,  -2.64908795e-01,\n",
      "         -1.21845727e-01,   1.24294285e-01,  -2.60246785e-03,\n",
      "          1.69120247e-01,  -2.84134069e-01,  -1.77556633e-01,\n",
      "          1.47449704e-01,   7.88717376e-02,   2.80090092e-01,\n",
      "         -3.42853280e-08,   2.95966442e-01,  -1.07798550e-01,\n",
      "          1.17437344e-01,   2.89456981e-01,  -1.17301316e-01,\n",
      "         -5.20660684e-02,  -7.85846565e-02,  -8.07425924e-02,\n",
      "         -1.18319375e-01,   1.84028313e-02,   3.23279073e-01,\n",
      "          4.22065302e-02,   3.83576275e-01,  -7.18640814e-03,\n",
      "         -2.72531796e-01,  -2.09909869e-01,  -6.18343740e-03,\n",
      "         -2.38224543e-01,   1.06873887e-01,  -1.02253317e-01,\n",
      "         -3.05599047e-01,  -1.62806477e-01,  -3.33456062e-01,\n",
      "          2.61264377e-01,   2.87291253e-01,  -9.57873075e-02,\n",
      "          1.98145839e-01,  -2.53857727e-01,  -7.16263443e-07,\n",
      "         -2.10040472e-01,  -3.80099283e-01,   8.24980404e-02,\n",
      "          3.19716625e-01,  -1.16542406e-01,   5.54326613e-02,\n",
      "          6.97238683e-02,  -3.32328825e-01,   8.29526830e-02,\n",
      "         -1.72339762e-01,  -2.06730828e-01,  -2.63702098e-01,\n",
      "          1.44673259e-01,  -2.63237144e-01,   5.93153595e-02,\n",
      "         -3.28890026e-01,   2.37666029e-01,   2.59939056e-01,\n",
      "         -1.14880438e-02,  -1.48848197e-01,  -3.40574186e-01,\n",
      "          3.12962081e-02,   5.90589377e-02,  -1.31188316e-01,\n",
      "         -2.47117751e-01,  -2.09847571e-01,  -3.72509661e-01,\n",
      "          1.16140497e-01,   1.87015108e-01,  -1.80585490e-01,\n",
      "          1.18796590e-01,   9.72941369e-02,   3.56674896e-01,\n",
      "         -2.57021356e-01,  -1.05683906e-03,   1.79798031e-01,\n",
      "         -3.12589432e-01,  -2.63818094e-01,   2.09769930e-01,\n",
      "         -3.20801651e-01,   1.00578571e-01,   4.41966626e-03,\n",
      "          2.43349960e-01,   1.88548382e-01,   2.24674420e-05,\n",
      "         -8.04259947e-02],\n",
      "       [ -3.86863903e-02,  -2.60977241e-01,  -2.37410520e-01,\n",
      "          4.10941276e-06,  -1.92522744e-01,  -2.02850292e-02,\n",
      "          2.44895705e-01,   1.81377887e-01,  -3.00873900e-01,\n",
      "         -7.16827866e-07,  -2.54615601e-01,   4.84854511e-02,\n",
      "          6.23456495e-02,   3.36289897e-01,  -3.55687651e-01,\n",
      "         -6.49323810e-02,   1.36873948e-01,  -1.60987113e-01,\n",
      "         -2.85997050e-01,  -2.83987432e-01,  -7.54644763e-02,\n",
      "         -4.30926932e-02,   4.99118934e-02,   2.63732530e-01,\n",
      "         -1.22451129e-03,  -1.38227621e-01,   3.17056929e-02,\n",
      "          1.68632009e-03,   2.06882297e-01,   1.01475648e-01,\n",
      "         -8.33423275e-02,   4.91247035e-02,   3.26891090e-01,\n",
      "          6.27445084e-02,  -1.12728242e-01,  -2.58009205e-01,\n",
      "         -3.16346807e-03,   8.11542749e-02,  -5.36672358e-05,\n",
      "         -2.72191150e-01,   4.03356050e-01,   5.37238945e-06,\n",
      "         -2.38124970e-01,   1.05777771e-01,   2.70661918e-01,\n",
      "          3.02461102e-01,  -2.41843604e-01,   4.42395299e-01,\n",
      "          3.02058001e-01,  -2.06465978e-01,   2.84013307e-01,\n",
      "          1.05395543e-01,   3.64033803e-01,   3.27277332e-07,\n",
      "         -2.10899263e-01,  -2.15059609e-01,   2.36548103e-01,\n",
      "         -1.40031228e-01,   3.49807195e-01,   6.52080855e-02,\n",
      "         -1.18571052e-01,  -3.32837643e-01,   2.40611626e-01,\n",
      "          3.45379028e-01,   3.57236496e-01,   2.41196017e-02,\n",
      "          1.84540862e-01,   3.77536408e-01,   2.81923308e-01,\n",
      "         -3.28684370e-01,   1.15341856e-01,   2.79809940e-01,\n",
      "         -1.26413650e-01,   9.85328963e-02,  -1.60469099e-01,\n",
      "         -3.89486285e-07,   1.02727595e-02,   1.18370829e-02,\n",
      "          3.73275879e-01,  -2.09817927e-01,  -2.37390346e-01,\n",
      "          1.60360346e-02,  -2.50548635e-03,  -5.35387622e-02,\n",
      "          1.03874621e-01,   9.55408278e-02,  -1.87739131e-01,\n",
      "         -2.87028808e-01,   1.51482177e-06,  -1.22205192e-01,\n",
      "         -3.12882186e-01,  -2.84535321e-01,  -2.52610506e-01,\n",
      "         -1.86802263e-01,   1.35977763e-01,   1.68383740e-01,\n",
      "          8.39382405e-02,  -3.22650770e-02,   1.34163727e-07,\n",
      "          2.84166086e-01]]), array([[  1.33086527e-01],\n",
      "       [ -1.82003616e-01],\n",
      "       [ -1.41289030e-01],\n",
      "       [  8.44519258e-09],\n",
      "       [ -3.21357203e-01],\n",
      "       [  3.72640573e-01],\n",
      "       [  3.25392684e-01],\n",
      "       [  3.33299315e-01],\n",
      "       [ -2.98636820e-01],\n",
      "       [  6.80717606e-02],\n",
      "       [ -3.24544375e-01],\n",
      "       [  1.68321835e-02],\n",
      "       [ -9.97258397e-03],\n",
      "       [  2.43361623e-01],\n",
      "       [ -3.55229917e-01],\n",
      "       [  3.66651971e-02],\n",
      "       [  4.46213958e-02],\n",
      "       [ -1.18215360e-01],\n",
      "       [  9.87981627e-02],\n",
      "       [ -2.20096546e-01],\n",
      "       [  1.14052323e-01],\n",
      "       [ -3.79541790e-02],\n",
      "       [ -4.25421380e-02],\n",
      "       [  3.00576753e-01],\n",
      "       [ -7.12390768e-03],\n",
      "       [  3.72649899e-01],\n",
      "       [ -1.06818701e-01],\n",
      "       [  2.58877739e-01],\n",
      "       [  1.41705836e-01],\n",
      "       [ -5.55747662e-02],\n",
      "       [ -1.07602301e-01],\n",
      "       [  8.00950516e-02],\n",
      "       [  1.68016777e-01],\n",
      "       [ -4.06223799e-02],\n",
      "       [ -5.05523157e-02],\n",
      "       [  3.84588065e-01],\n",
      "       [ -1.19140623e-01],\n",
      "       [  3.42059112e-01],\n",
      "       [  2.25306634e-03],\n",
      "       [ -2.21360969e-01],\n",
      "       [  1.72736638e-01],\n",
      "       [  7.15621305e-02],\n",
      "       [ -4.09848019e-01],\n",
      "       [ -1.70888933e-01],\n",
      "       [  1.72644970e-01],\n",
      "       [  2.24337534e-01],\n",
      "       [ -3.87218363e-01],\n",
      "       [  1.70023042e-01],\n",
      "       [  1.60185127e-01],\n",
      "       [  3.04183985e-01],\n",
      "       [  3.15103193e-01],\n",
      "       [  1.94739054e-01],\n",
      "       [  2.67681398e-01],\n",
      "       [ -5.34300427e-02],\n",
      "       [ -3.82293544e-01],\n",
      "       [ -2.11437244e-01],\n",
      "       [  3.08118553e-01],\n",
      "       [  2.82566156e-01],\n",
      "       [  3.45490556e-01],\n",
      "       [ -1.00807097e-01],\n",
      "       [ -2.95617624e-02],\n",
      "       [ -1.67550021e-01],\n",
      "       [  3.31211946e-01],\n",
      "       [  2.76895051e-01],\n",
      "       [  3.06577049e-01],\n",
      "       [ -4.62987610e-02],\n",
      "       [  1.82485998e-01],\n",
      "       [  3.06174717e-01],\n",
      "       [  1.55238664e-01],\n",
      "       [ -3.51865669e-01],\n",
      "       [  3.71676257e-01],\n",
      "       [  3.29721213e-01],\n",
      "       [ -1.70772520e-01],\n",
      "       [ -7.82683005e-02],\n",
      "       [ -3.52096825e-01],\n",
      "       [  5.79626424e-02],\n",
      "       [ -2.13101906e-01],\n",
      "       [ -1.47988798e-01],\n",
      "       [  1.54405382e-01],\n",
      "       [ -2.85764439e-01],\n",
      "       [ -2.18197208e-01],\n",
      "       [  3.38744532e-01],\n",
      "       [ -2.87507945e-02],\n",
      "       [ -1.91284780e-01],\n",
      "       [ -5.07780725e-02],\n",
      "       [ -1.43337775e-01],\n",
      "       [  2.45900304e-01],\n",
      "       [ -1.87895116e-01],\n",
      "       [ -1.52726801e-03],\n",
      "       [  5.50250074e-02],\n",
      "       [ -3.61725371e-01],\n",
      "       [ -1.81135626e-01],\n",
      "       [  3.35216311e-01],\n",
      "       [ -3.98324487e-01],\n",
      "       [  3.36355593e-01],\n",
      "       [ -1.07073709e-02],\n",
      "       [  3.01113095e-01],\n",
      "       [  2.99463591e-01],\n",
      "       [ -2.81429419e-02],\n",
      "       [  3.24194479e-01]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlp = MLPClassifier() # set the method\n",
    "mlp.fit(X_training, y_training)                    # training\n",
    "y_pred=mlp.predict(X_training)                      # prediction\n",
    "print(y_pred)                                      # show the output\n",
    "print([coef.shape for coef in mlp.coefs_])  # size of synapsis weights\n",
    "print(mlp.coefs_)                                 # synapsis weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now your Turn!\n",
    "### Experiments\n",
    "\n",
    "-  Change the data (X_training, y_training, X_testing)\n",
    "-  Change the hidden layer of MLP: number of layers (int) or size (n,m)\n",
    "-  Change activation function of MLP: {'identity', 'logistic', 'tanh', 'relu'}, default 'relu'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "import sklearn.metrics as metric\n",
    "import numpy as np\n",
    "\n",
    "X_training=[[1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_training=[1, \n",
    "            1,\n",
    "            1,\n",
    "            0\n",
    "           ]\n",
    "X_testing = X_training\n",
    "y_true = y_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n",
      "acuracy= 0.75\n",
      "[(2, 200), (200, 100), (100, 300), (300, 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(200,100,300 ), activation='logistic') # set the method\n",
    "mlp.fit(X_training, y_training)                    # training\n",
    "y_pred=mlp.predict(X_testing)                      # prediction\n",
    "print(y_pred)                                      # show the output\n",
    "accuracy=metric.accuracy_score(np.array(y_true).flatten(), np.array(y_pred).flatten(), normalize=True)\n",
    "print('acuracy=',accuracy)                         # show accracy score\n",
    "\n",
    "\n",
    "print([coef.shape for coef in mlp.coefs_])  # size of synapsis weights\n",
    "len(mlp.coefs_)                                  # synapsis weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XNOR \n",
    "Try solve the following Boolean Exclusive Not Or (XNOR) problem. How to improve the accuracy? How many minimum hidden layer is needed to make it 100% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuracy= 0.25\n",
      "[(2, 50), (50, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_training=[[1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_training=[1, \n",
    "            0,\n",
    "            0,\n",
    "            0\n",
    "           ]\n",
    "X_testing=X_training\n",
    "y_true=y_training\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50)) # set the method\n",
    "mlp.fit(X_training, y_training)                    # training\n",
    "                                      # show the output\n",
    "accuracy=metric.accuracy_score(np.array(y_true).flatten(), np.array(y_pred).flatten(), normalize=True)\n",
    "print('acuracy=',accuracy)                         # show accracy score\n",
    "\n",
    "\n",
    "print([coef.shape for coef in mlp.coefs_])  # size of synapsis weights\n",
    "len(mlp.coefs_)                                  # synapsis weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95999999999999996"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"iris.csv\")\n",
    "features = train.columns[:-1]\n",
    "X = train[features]\n",
    "Y =train['Species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5)\n",
    "nn = MLPClassifier()\n",
    "a = nn.fit(X_train,y_train)\n",
    "nn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "Creat your network based on only two features of the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'C:\\\\Users\\\\mahsa\\\\Desktop\\\\iris.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b1a2865327b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"C:\\Users\\mahsa\\Desktop\\iris.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'C:\\\\Users\\\\mahsa\\\\Desktop\\\\iris.csv' does not exist"
     ]
    }
   ],
   "source": [
    "#your answer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "train = pd.read_csv(r\"C:\\Users\\mahsa\\Desktop\\iris.csv\")\n",
    "features = train.columns[:-1]\n",
    "X = train[features]\n",
    "Y =train['Species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5)\n",
    "nn = MLPClassifier()\n",
    "a = nn.fit(X_train,y_train)\n",
    "nn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to create and train a nerural network for a given dataset with higher accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "train = pd.read_csv(r\"C:\\Users\\mahsa\\Desktop\\iris.csv\")\n",
    "features = train.columns[:-1]\n",
    "X = train[features]\n",
    "Y =train['Species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5)\n",
    "nn = MLPClassifier()\n",
    "a = nn.fit(X_train,y_train)\n",
    "nn.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
