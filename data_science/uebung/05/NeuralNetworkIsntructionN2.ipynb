{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Nework\n",
    "here we try to write a simple neural network to understand what backpropagation really do :)\n",
    "## Now we create a simple one layer newtork "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### continue our feedforward network and make it a complete neural network that can predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.50094421]\n",
      " [ 0.49639754]\n",
      " [ 0.48625802]\n",
      " [-0.50998644]]\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      "[[ 0.50094421]\n",
      " [ 0.50360246]\n",
      " [ 0.51374198]\n",
      " [ 0.50998644]]\n"
     ]
    }
   ],
   "source": [
    "#activation funcion\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "#derivative of activation funcion\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1.0 - x)\n",
    "    #return sigmoid(x) * (1.0 - sigmoid(x)) #laut Folien ist das die Formel\n",
    "\n",
    "#class of your neural network\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    #set features of your neural network\n",
    "    def __init__(self, x, y):\n",
    "        self.input      = x\n",
    "        self.weights1   = np.random.rand(self.input.shape[1],2)\n",
    "        self.weights2   = np.random.rand(2,1)          \n",
    "        self.y          = y\n",
    "        self.output     = np.zeros(self.y.shape)\n",
    "    #feedfarward function \n",
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "    #backpropagate the error\n",
    "    def backprop(self):\n",
    "        # application of the chain rule to find derivative of the Error with respect to weights2 and weights1\n",
    "        d_weights2 = np.dot(self.layer1.T, ((self.y - self.output) * sigmoid_derivative(self.output)))\n",
    "        d_weights1 = np.dot(self.input.T,  (np.dot((self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1)))\n",
    "\n",
    "        # update the weights with the derivative (slope) of the loss function\n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2\n",
    "\n",
    "#Test what you have done :D \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X = np.array([[0,0,1],\n",
    "                  [0,1,1],\n",
    "                  [1,0,1],\n",
    "                  [1,1,1]])\n",
    "    y = np.array([[0],[1],[1],[0]])\n",
    "   \n",
    "    nn = NeuralNetwork(X, y) # make instance of your NerualNetwork class\n",
    "   \n",
    "    #do the iteration for learning\n",
    "    for i in range(100):\n",
    "        nn.feedforward()\n",
    "        nn.backprop()\n",
    "        \n",
    "    print(nn.y - nn.output)\n",
    "    print(nn.y)\n",
    "    print(nn.output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0,0,1],\n",
    "                  [0,1,1],\n",
    "                  [1,0,1],\n",
    "                  [1,1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.62280303,  0.82768106],\n",
       "       [ 0.41043887,  0.80316101],\n",
       "       [ 0.07218135,  0.09321666]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights1   = np.random.rand(X.shape[1],2)\n",
    "weights1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07218135,  0.09321666],\n",
       "       [ 0.48262022,  0.89637767],\n",
       "       [ 0.69498438,  0.92089771],\n",
       "       [ 1.10542325,  1.72405872]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X, weights1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Useful Libraries\n",
    "Simple Example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [[0], [1]]\n",
    "clf = MLPClassifier()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict([[1, 2]]))\n",
    "print(clf.predict([[0, 0]]))\n",
    "print(clf.predict([[1, 1]]))\n",
    "print(clf.predict([[0, 2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR Function\n",
    "Let us start with a simple example of Boolean OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "import sklearn.metrics as metric\n",
    "import numpy as np\n",
    "\n",
    "X_training=[]\n",
    "y_training=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_training=[[1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_training=[1, \n",
    "            1,\n",
    "            1,\n",
    "            0\n",
    "           ]\n",
    "mlp = MLPClassifier() # set the method\n",
    "mlp.fit(X_training, y_training)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(mlp.predict([[0,0]]))\n",
    "print(mlp.predict([[0,1]]))\n",
    "print(mlp.predict([[1,0]]))\n",
    "print(mlp.predict([[1,1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice: Bipolar OR\n",
    "\n",
    "Instead of {0, 1}, we can also change the value into bipolar {-1, +1}. Try the following OR gate using Perceptron and MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_training=[[1, 1], \n",
    "            [1, -1],\n",
    "            [-1, 1],\n",
    "            [-1, -1]\n",
    "           ]\n",
    "y_training=[1, \n",
    "            1,\n",
    "            1,\n",
    "            -1\n",
    "           ]\n",
    "X_testing=X_training\n",
    "y_true=y_training\n",
    "\n",
    "mlp_bipolar = MLPClassifier() # set the method\n",
    "mlp_bipolar.fit(X_testing, y_true)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(mlp_bipolar.predict([[-1,-1]]))\n",
    "print(mlp_bipolar.predict([[-1,1]]))\n",
    "print(mlp_bipolar.predict([[1,-1]]))\n",
    "print(mlp_bipolar.predict([[1,1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Networks\n",
    "\n",
    "The following code is the example of how you will use Multi-Layer Perceptron (MLP) Neural Network to train, predict. You can also get the weights of the Neural Network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1 -1]\n",
      "[(2, 100), (100, 1)]\n",
      "[array([[  2.35757334e-01,  -8.97010834e-08,   9.12256896e-02,\n",
      "         -1.13559796e-01,   3.62386552e-01,  -4.84050692e-02,\n",
      "          1.78576540e-02,   1.48151180e-01,   1.46341184e-01,\n",
      "         -2.96656228e-02,   6.01060462e-02,  -5.69960004e-03,\n",
      "         -1.93370682e-01,  -8.40378550e-02,  -2.41938825e-01,\n",
      "         -2.50806976e-01,   1.90432286e-01,  -3.41069149e-01,\n",
      "          5.02273255e-02,   2.25970409e-01,   1.40400742e-01,\n",
      "         -5.88745125e-02,  -5.05880767e-02,  -1.21142813e-01,\n",
      "         -1.19552891e-01,   1.60787323e-01,  -1.82672984e-01,\n",
      "         -1.07292621e-01,  -9.03739002e-09,  -6.21365265e-02,\n",
      "         -5.44931870e-08,   2.28960802e-01,  -1.65419275e-01,\n",
      "          3.53959884e-01,   2.70069269e-01,  -7.07954298e-02,\n",
      "         -1.36672060e-01,   7.24479829e-03,   9.68212052e-06,\n",
      "         -3.36610733e-01,   1.85994009e-01,   4.79233284e-01,\n",
      "         -1.08987340e-01,   4.02289892e-01,   1.49630633e-01,\n",
      "          2.90188530e-01,  -2.15715801e-07,  -1.20532248e-01,\n",
      "          9.25278078e-02,   1.11255946e-01,  -2.73630456e-01,\n",
      "          7.67515858e-06,  -3.03565716e-01,  -9.74346291e-02,\n",
      "         -3.28681408e-01,  -9.52082880e-03,   1.05958035e-03,\n",
      "          4.18274549e-01,   1.35255411e-01,  -3.33915197e-01,\n",
      "          2.83378476e-01,   1.75798044e-01,  -9.09057713e-02,\n",
      "          2.03834938e-01,   8.83559062e-02,  -8.86470890e-02,\n",
      "         -2.55238672e-01,   3.04468664e-02,  -1.97683831e-01,\n",
      "          1.54833412e-01,   1.38711054e-03,   1.09911865e-01,\n",
      "          1.41606811e-01,  -1.88396601e-01,   6.91262489e-03,\n",
      "          2.00643950e-01,  -3.39677271e-01,  -1.75056025e-01,\n",
      "          1.72928900e-03,   3.31260501e-07,   3.30289458e-01,\n",
      "         -2.28076995e-01,  -2.18185156e-02,   1.19353888e-01,\n",
      "         -2.07601398e-01,  -8.40076350e-02,   1.56817701e-01,\n",
      "         -3.06804131e-01,  -3.83871409e-01,  -2.24823051e-01,\n",
      "          2.74899012e-01,  -2.29391212e-01,   3.50731517e-01,\n",
      "         -3.83872682e-02,  -3.17865490e-02,  -7.58974793e-02,\n",
      "         -2.68414593e-01,   2.94159248e-01,   3.82004677e-01,\n",
      "         -2.49671981e-02],\n",
      "       [ -1.67726790e-01,   1.05669946e-06,  -5.30981039e-03,\n",
      "          7.12167462e-02,  -6.43541580e-02,  -6.69946965e-02,\n",
      "          3.51242588e-01,   6.71886822e-02,   1.47923647e-01,\n",
      "          2.70443369e-01,  -1.74584197e-01,   1.53215236e-01,\n",
      "         -2.78546449e-01,   1.33760600e-01,  -2.58131212e-01,\n",
      "          1.57170244e-01,  -2.14315634e-02,  -3.66647252e-01,\n",
      "          1.00309885e-01,  -2.79258837e-02,  -2.88930467e-01,\n",
      "         -2.29961076e-01,   1.45350122e-01,  -3.41857730e-01,\n",
      "         -3.05274125e-01,   9.37545442e-02,   3.67794087e-01,\n",
      "          2.29455714e-02,   7.27002295e-03,   2.38157096e-01,\n",
      "          1.26539954e-06,   2.03151059e-01,   3.05630923e-01,\n",
      "         -1.55652717e-01,  -1.11473154e-01,  -5.80046625e-02,\n",
      "         -1.24831596e-01,   1.93459503e-07,  -9.91564978e-07,\n",
      "         -3.37971780e-01,  -7.94964726e-02,   1.43958911e-01,\n",
      "         -3.78184652e-02,  -1.23998771e-01,  -5.29916907e-03,\n",
      "          1.97458067e-01,  -4.89764648e-06,   4.12929596e-01,\n",
      "          5.82529346e-02,   1.10372010e-01,  -1.87827891e-01,\n",
      "         -3.65984029e-04,  -4.05892257e-01,   2.49228533e-03,\n",
      "         -2.60571398e-02,   1.47220475e-01,  -2.16080806e-01,\n",
      "         -8.43018075e-02,   3.97594566e-01,  -3.33095745e-01,\n",
      "          8.04662307e-02,   7.26507196e-02,  -8.31818395e-02,\n",
      "          1.25009462e-02,  -9.79570517e-02,   3.51300670e-01,\n",
      "          9.23964379e-02,   1.64355170e-01,   4.39307401e-01,\n",
      "         -8.97077844e-03,  -1.95221969e-01,   1.37770552e-01,\n",
      "          7.88107869e-02,   2.98109198e-01,  -1.59726044e-05,\n",
      "         -1.68706362e-01,  -3.39644123e-01,   1.52469207e-01,\n",
      "         -7.72626820e-02,  -1.47175681e-03,   1.24096316e-02,\n",
      "         -1.73990246e-01,  -4.66620852e-03,  -3.12525260e-01,\n",
      "         -2.07461329e-01,   8.79995676e-02,   9.27799431e-02,\n",
      "         -2.64674907e-01,  -1.59692739e-01,   3.48181387e-01,\n",
      "          1.53215257e-01,   3.67744393e-01,  -2.34881555e-02,\n",
      "          1.78929737e-01,  -1.92830759e-01,   2.37498027e-01,\n",
      "          8.29943776e-02,   1.16732586e-01,  -1.88942043e-01,\n",
      "          8.73145026e-02]]), array([[  2.25173735e-01],\n",
      "       [  1.12358701e-06],\n",
      "       [ -9.20810043e-02],\n",
      "       [ -9.71006664e-02],\n",
      "       [  3.10852272e-01],\n",
      "       [  2.51343238e-02],\n",
      "       [  2.05825000e-01],\n",
      "       [ -3.23582089e-02],\n",
      "       [ -3.76208399e-03],\n",
      "       [  3.59168637e-01],\n",
      "       [ -4.26116257e-02],\n",
      "       [  4.21109778e-01],\n",
      "       [ -2.58785415e-01],\n",
      "       [ -9.93673186e-02],\n",
      "       [ -1.12477265e-01],\n",
      "       [  2.66063269e-01],\n",
      "       [  2.72917624e-01],\n",
      "       [ -2.43188436e-01],\n",
      "       [ -5.36726726e-02],\n",
      "       [  6.12918769e-02],\n",
      "       [ -7.36505168e-02],\n",
      "       [ -5.76236024e-02],\n",
      "       [ -1.87356519e-01],\n",
      "       [ -3.86115937e-01],\n",
      "       [ -3.23275828e-01],\n",
      "       [ -4.65707508e-02],\n",
      "       [  2.21129376e-01],\n",
      "       [  1.55475908e-01],\n",
      "       [  4.48980722e-02],\n",
      "       [  2.48972556e-01],\n",
      "       [  7.38946297e-07],\n",
      "       [  2.68158512e-01],\n",
      "       [  1.94424269e-01],\n",
      "       [  2.95291315e-01],\n",
      "       [  3.70842104e-01],\n",
      "       [  1.33162321e-01],\n",
      "       [  1.80232947e-02],\n",
      "       [  1.70217161e-05],\n",
      "       [  3.67412194e-06],\n",
      "       [ -2.37236042e-01],\n",
      "       [  3.54021597e-01],\n",
      "       [  1.54693595e-01],\n",
      "       [  1.83878794e-01],\n",
      "       [  1.54677982e-01],\n",
      "       [ -1.00901061e-01],\n",
      "       [  2.11187509e-01],\n",
      "       [ -6.02412482e-02],\n",
      "       [  1.26573499e-01],\n",
      "       [ -1.02974394e-01],\n",
      "       [ -1.40467636e-01],\n",
      "       [ -4.40690583e-01],\n",
      "       [ -5.81488500e-02],\n",
      "       [ -2.52674477e-01],\n",
      "       [  1.61370813e-01],\n",
      "       [ -1.16506109e-01],\n",
      "       [ -1.78034683e-01],\n",
      "       [ -7.84109171e-02],\n",
      "       [  1.65943125e-01],\n",
      "       [  3.77049924e-01],\n",
      "       [ -1.66199941e-01],\n",
      "       [  1.72082470e-01],\n",
      "       [ -4.66467553e-02],\n",
      "       [ -2.42205481e-01],\n",
      "       [ -7.78450022e-02],\n",
      "       [ -3.88661643e-02],\n",
      "       [  2.64804413e-01],\n",
      "       [ -1.09387073e-01],\n",
      "       [  2.78620977e-01],\n",
      "       [  1.68467142e-01],\n",
      "       [  2.61432019e-02],\n",
      "       [ -5.84830224e-02],\n",
      "       [ -1.17434396e-01],\n",
      "       [ -1.14941617e-01],\n",
      "       [  3.16615596e-01],\n",
      "       [ -3.26294604e-02],\n",
      "       [  3.65075339e-01],\n",
      "       [ -2.05525448e-01],\n",
      "       [  3.70386092e-01],\n",
      "       [ -5.33873651e-03],\n",
      "       [  1.40028535e-04],\n",
      "       [  3.80745141e-01],\n",
      "       [ -4.29531780e-01],\n",
      "       [ -1.56859836e-01],\n",
      "       [ -4.23259075e-02],\n",
      "       [ -2.43039043e-01],\n",
      "       [ -2.77376778e-02],\n",
      "       [  2.86594565e-01],\n",
      "       [ -2.68218443e-01],\n",
      "       [ -2.53431561e-01],\n",
      "       [  2.65527467e-01],\n",
      "       [  3.65539917e-01],\n",
      "       [  3.09897967e-01],\n",
      "       [  2.34160928e-01],\n",
      "       [  3.16392253e-01],\n",
      "       [ -1.43016678e-01],\n",
      "       [  1.19382834e-01],\n",
      "       [ -1.61210350e-01],\n",
      "       [  3.08522896e-01],\n",
      "       [  2.81325677e-01],\n",
      "       [ -8.69535939e-02]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlp = MLPClassifier() # set the method\n",
    "mlp.fit(X_training, y_training)                    # training\n",
    "y_pred=mlp.predict(X_training)                      # prediction\n",
    "print(y_pred)                                      # show the output\n",
    "print([coef.shape for coef in mlp.coefs_])  # size of synapsis weights\n",
    "print(mlp.coefs_)                                 # synapsis weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now your Turn!\n",
    "### Experiments\n",
    "\n",
    "-  Change the data (X_training, y_training, X_testing)\n",
    "-  Change the hidden layer of MLP: number of layers (int) or size (n,m)\n",
    "-  Change activation function of MLP: {'identity', 'logistic',...}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "import sklearn.metrics as metric\n",
    "import numpy as np\n",
    "\n",
    "X_training=[[1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_training=[1, \n",
    "            1,\n",
    "            1,\n",
    "            0\n",
    "           ]\n",
    "\n",
    "X_testing = X_training\n",
    "y_true = y_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n",
      "acuracy= 0.75\n",
      "[(2, 200), (200, 100), (100, 300), (300, 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(200,100,300), activation='logistic') # set the method\n",
    "mlp.fit(X_training, y_training)                    # training\n",
    "y_pred=mlp.predict(X_testing)                      # prediction\n",
    "print(y_pred)                                      # show the output\n",
    "accuracy=metric.accuracy_score(np.array(y_true).flatten(), np.array(y_pred).flatten(), normalize=True)\n",
    "print('acuracy=', accuracy)                         # show accracy score\n",
    "\n",
    "\n",
    "print([coef.shape for coef in mlp.coefs_])  # size of synapsis weights\n",
    "len(mlp.coefs_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XNOR \n",
    "Try solve the following Boolean Exclusive Not Or (XNOR) problem. How to improve the accuracy? How many minimum hidden layer is needed to make it 100% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training=[[1, 1], \n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_training=[1, \n",
    "            0,\n",
    "            0,\n",
    "            0\n",
    "           ]\n",
    "X_testing=X_training\n",
    "y_true=y_training    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0]\n",
      "[1 1 1 1]\n",
      "acuracy= 0.25\n",
      "[(2, 50), (50, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(50)) # set the method\n",
    "mlp.fit(X_training, y_training)                    # training\n",
    "                                      # show the output\n",
    "print(np.array(y_true).flatten())\n",
    "print(np.array(y_pred).flatten())\n",
    "accuracy=metric.accuracy_score(np.array(y_true).flatten(), np.array(y_pred).flatten(), normalize=True)\n",
    "print('acuracy=',accuracy)                         # show accracy score\n",
    "\n",
    "\n",
    "print([coef.shape for coef in mlp.coefs_])  # size of synapsis weights\n",
    "len(mlp.coefs_)                                  # synapsis weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = pd.read_csv(\"iris.csv\")\n",
    "train=pd.get_dummies(train)\n",
    "features = train.columns[:-1]\n",
    "y = train.columns[-1]\n",
    "Y =(train[y])\n",
    "X = train[features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5)\n",
    "nn = MLPClassifier()\n",
    "nn.fit(X_train,y_train)\n",
    "nn.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "Creat your network based on only two features of the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98666666666666669"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your answer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"iris.csv\")\n",
    "features = train.columns[:-1]\n",
    "X = train[features]\n",
    "Y =train['Species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5)\n",
    "nn = MLPClassifier()\n",
    "a = nn.fit(X_train,y_train)\n",
    "nn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to create and train a nerural network for a given dataset with higher accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97333333333333338"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your answer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"iris.csv\")\n",
    "features = train.columns[:-1]\n",
    "X = train[features]\n",
    "Y =train['Species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5)\n",
    "nn = MLPClassifier()\n",
    "a = nn.fit(X_train,y_train)\n",
    "nn.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
